{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aymane/Kaggle/jpx-2022/venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import helper_functions as hf\n",
    "from dataloader import JPXData\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torchvision import transforms\n",
    "from statistics import mean\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "# pd.set_option('display.max_rows', 100)\n",
    "torch.set_printoptions(profile=\"default\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to create the new modified_data folder\n",
    "# ~ 1 min runtime\n",
    "\n",
    "# hf.concat_data()\n",
    "\n",
    "# Run this to tokenize Section/Product and NewMarketSegmentColumns on stock_list.csv\n",
    "# ~ 20 secs runtime\n",
    "\n",
    "# hf.tokenize_stock_list()\n",
    "\n",
    "# Run this to adjust the closing price\n",
    "# ~ 2 mins runtime\n",
    "\n",
    "# hf.adjust_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices = pd.read_csv(\"modified_data/autoencoder_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ 3 month testing time frame 2022-01-04 to 2022-04-28\n",
    "train_data = stock_prices[stock_prices[\"Date\"] < '2022-01-04'].copy().reset_index(drop=True)\n",
    "test_data  = stock_prices[stock_prices[\"Date\"] >= '2022-01-04'].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aymane/Kaggle/jpx-2022/dataloader.py:148: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  means_stds = torch.tensor([np.array(calc_mean_std(code)) for code in self.stock_id.tolist()],dtype=torch.float)\n",
      "/home/aymane/Kaggle/jpx-2022/dataloader.py:100: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  data = np.array([calc_io(date) for date in self.dates])\n",
      "/home/aymane/Kaggle/jpx-2022/dataloader.py:100: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array([calc_io(date) for date in self.dates])\n",
      "/home/aymane/Kaggle/jpx-2022/dataloader.py:100: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  data = np.array([calc_io(date) for date in self.dates])\n",
      "/home/aymane/Kaggle/jpx-2022/dataloader.py:100: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array([calc_io(date) for date in self.dates])\n",
      "/home/aymane/Kaggle/jpx-2022/dataloader.py:100: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  data = np.array([calc_io(date) for date in self.dates])\n",
      "/home/aymane/Kaggle/jpx-2022/dataloader.py:100: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array([calc_io(date) for date in self.dates])\n"
     ]
    }
   ],
   "source": [
    "train_class = JPXData(data=train_data)\n",
    "trainloader = torch.utils.data.DataLoader(train_class, batch_size=1, shuffle=True, num_workers=5)\n",
    "test_class  = JPXData(data=test_data, train=False)\n",
    "testloader  = torch.utils.data.DataLoader(JPXData(data=test_data), batch_size=1, shuffle=False, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.0993493 , -0.00413453,  0.06098191, ...,  0.02222464,\n",
       "        -0.28374362, -0.08658674], dtype=float32),\n",
       " 0.0061527328,\n",
       " ['2021-12-30'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class[1220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>-0.069874</td>\n",
       "      <td>9474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>-0.067387</td>\n",
       "      <td>9983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>-0.062112</td>\n",
       "      <td>6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>-0.059276</td>\n",
       "      <td>9974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>-0.057514</td>\n",
       "      <td>6707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>0.094378</td>\n",
       "      <td>9233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.098553</td>\n",
       "      <td>3547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.104668</td>\n",
       "      <td>6425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>0.106332</td>\n",
       "      <td>7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.175676</td>\n",
       "      <td>3825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1865 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target  SecuritiesCode\n",
       "1733 -0.069874            9474\n",
       "1856 -0.067387            9983\n",
       "1136 -0.062112            6875\n",
       "1852 -0.059276            9974\n",
       "1078 -0.057514            6707\n",
       "...        ...             ...\n",
       "1695  0.094378            9233\n",
       "404   0.098553            3547\n",
       "1000  0.104668            6425\n",
       "1297  0.106332            7600\n",
       "457   0.175676            3825\n",
       "\n",
       "[1865 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking Securities Codes by rate of change from t+1 to t+2\n",
    "stock_prices = pd.read_csv(\"modified_data/stock_prices.csv\")\n",
    "date = \"2017-01-04\"\n",
    "targets = stock_prices.query(\"Date == @date\")[[\"Target\", \"SecuritiesCode\"]].fillna(0)\n",
    "df = targets.sort_values(by=\"Target\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138000\n"
     ]
    }
   ],
   "source": [
    "a = train_class\n",
    "print(len(a[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verifying if the ranking is the same\n",
    "# securities_codes    = stock_prices[\"SecuritiesCode\"]\n",
    "# securities_list     = sorted(list(set(securities_codes)))\n",
    "# securities_dict     = {i: securities_list.index(i) for i in securities_list}\n",
    "\n",
    "# a = dataloader[0][1]\n",
    "# sorted_args = torch.argsort(a, descending=True)\n",
    "# securities_sort = [list(securities_dict.keys())[list(securities_dict.values()).index(i)] for i in sorted_args]\n",
    "# print(securities_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "69*2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Linear(138000, 7000),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Linear(7000, 5000),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Linear(5000, 2000),\n",
    "            # nn.LeakyReLU(negative_slope=0.1),\n",
    "            # nn.Linear(1000, 1500),\n",
    "            # nn.LeakyReLU(negative_slope=0.1),\n",
    "            # nn.Linear(1500, 2000),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.layer_stack(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aymane/Kaggle/jpx-2022/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:981: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 2000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.huber_loss(input, target, reduction=self.reduction, delta=self.delta)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.60 GiB (GPU 0; 5.80 GiB total capacity; 3.99 GiB already allocated; 540.12 MiB free; 4.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/aymane/Kaggle/jpx-2022/training.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/aymane/Kaggle/jpx-2022/training.ipynb#ch0000012?line=15'>16</a>\u001b[0m outputs \u001b[39m=\u001b[39m net(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/aymane/Kaggle/jpx-2022/training.ipynb#ch0000012?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m hf\u001b[39m.\u001b[39mloss_function(outputs \u001b[39m*\u001b[39m \u001b[39m10\u001b[39m, labels \u001b[39m*\u001b[39m \u001b[39m10\u001b[39m, criterion\u001b[39m=\u001b[39mnn\u001b[39m.\u001b[39mHuberLoss(delta\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/aymane/Kaggle/jpx-2022/training.ipynb#ch0000012?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/aymane/Kaggle/jpx-2022/training.ipynb#ch0000012?line=18'>19</a>\u001b[0m \u001b[39m# torch.nn.utils.clip_grad_norm_(net.parameters(), 1.5)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/aymane/Kaggle/jpx-2022/training.ipynb#ch0000012?line=19'>20</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Kaggle/jpx-2022/venv/lib/python3.10/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/Kaggle/jpx-2022/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.60 GiB (GPU 0; 5.80 GiB total capacity; 3.99 GiB already allocated; 540.12 MiB free; 4.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "loss_a1 = []\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels, date = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = hf.loss_function(outputs * 10, labels * 10, criterion=nn.HuberLoss(delta=5))\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(net.parameters(), 1.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        loss_a1.append(running_loss)\n",
    "        if i % 100 == 99:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.10f}')\n",
    "            running_loss = 0.0\n",
    "        # torch.save(net.state_dict(), f'saved_models/{epoch}.pt')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_a1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "dates = []\n",
    "securities = []\n",
    "preds = []\n",
    "targets = []\n",
    "\n",
    "stock_ids = test_class.stock_id.tolist()\n",
    "\n",
    "for X, target, date in tqdm(test_class):\n",
    "    X = X.cuda()\n",
    "    pred = net(X)\n",
    "\n",
    "    target_list = target.tolist()\n",
    "\n",
    "    dates.append(date*2000)\n",
    "    securities.append(stock_ids)\n",
    "    preds.append(pred.tolist())\n",
    "    targets.append(target_list)\n",
    "\n",
    "    new_dates = list(itertools.chain.from_iterable(dates))\n",
    "    new_securities = list(itertools.chain.from_iterable(securities))\n",
    "    new_preds = list(itertools.chain.from_iterable(preds))\n",
    "    new_targets = list(itertools.chain.from_iterable(targets))\n",
    "\n",
    "pred_df[\"Date\"] = new_dates\n",
    "pred_df[\"SecuritiesCode\"] = new_securities\n",
    "pred_df[\"Prediction\"] = new_preds\n",
    "pred_df[\"Target\"] = new_targets\n",
    "print(pred_df)\n",
    "# predictions = pd.DataFrame(list(zip(dates, securitiescodes, targets)), columns=[\"Date\", \"SecuritiesCode\", \"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pred_df.groupby(\"Date\")\n",
    "\n",
    "securities_dict = {i: stock_ids.index(i) for i in stock_ids}\n",
    "rank = []\n",
    "for i in tqdm(dates):\n",
    "    sorted_args = torch.argsort(torch.tensor(list(i[1][\"Prediction\"])), descending=True)\n",
    "    securities_sort = [list(securities_dict.keys())[list(securities_dict.values()).index(i)] for i in sorted_args]\n",
    "    sorted_ranks = [securities_sort.index(i) for i in stock_ids]\n",
    "    rank.append(sorted_ranks)\n",
    "\n",
    "new_rank = list(itertools.chain.from_iterable(rank))\n",
    "pred_df[\"Rank\"] = new_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.calc_spread_return_sharpe(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2db06da75207f0b335e9532cc533497eb90d83ed622a6d9d355f2997ed09f04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
